app = FastAPI()
templates = Jinja2Templates(directory="")
class static:
   user_data=None
   email=None
   full_name=None
   level=None
   path=None
   interest=None
   bills=[]
   total_chat_duration=0
   step='step1'
   history=[]
   vocabs=[]
   messages=[]
   last_response_time=None
   template2="""
   \n
   history:"""
def warmup(msg):
    prompt_template = PromptTemplate(input_variables=["chat_history","question"], template=static.template+static.template2)
    llm_chain = LLMChain(
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7,
        max_tokens=100, n=1),
        prompt=prompt_template,
        verbose=False,
        memory=static.memory,
   
        )
    start_time = time.time()  # Start the timer
    with get_openai_callback() as cb:
      result=llm_chain.predict(question=msg)
      static.bills.append(cb)
    end_time = time.time()  # End the timer

    result=result.replace('A2ZBot:','',-1).replace('AI:','',-1).replace('A2Zbot:','',-1)
    chat_time = end_time - start_time
    static.total_chat_duration+=chat_time
    last_response_time=end_time
    return result
def save_data():
	print('.............')